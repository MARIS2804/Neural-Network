{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b2b2b6b-55ef-4085-9a33-74910485e758",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "df=load_iris()\n",
    "df.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f284aeb-3fa1-48ca-ab4e-18bdae5e4689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1,\n",
       "       2, 0, 1, 2, 0, 2, 2, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 1, 0, 2, 0, 0,\n",
       "       1, 1, 2, 1, 2, 2, 1, 0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1,\n",
       "       2, 1, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0,\n",
       "       2, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 2, 0, 1, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=df.data\n",
    "y=df.target\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,shuffle=True,random_state=42,test_size=0.3)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35f9cf92-1088-46e6-837f-48c1f56bda38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Dense\n",
    "from keras import Sequential\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(units=40,input_dim=4,activation='relu'))\n",
    "model.add(Dense(units=80,activation='sigmoid'))\n",
    "model.add(Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f69fe25e-29c5-4de9-9a44-032eba42270a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer=\"sgd\",metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5200ebe0-c0da-4d23-bf81-b83e0f7df522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/6 [====>.........................] - ETA: 1s - loss: 0.0000e+00 - accuracy: 0.6500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1176: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 49/100\n",
      "6/6 [==============================] - 0s 996us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 996us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 996us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 996us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 64/100\n",
      "6/6 [==============================] - 0s 797us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 65/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 66/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 67/100\n",
      "6/6 [==============================] - 0s 797us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 68/100\n",
      "6/6 [==============================] - 0s 996us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 69/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 70/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 71/100\n",
      "6/6 [==============================] - 0s 797us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 72/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 73/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 74/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 75/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 76/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 77/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 78/100\n",
      "6/6 [==============================] - 0s 998us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 79/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 80/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 81/100\n",
      "6/6 [==============================] - 0s 798us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 82/100\n",
      "6/6 [==============================] - 0s 998us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 83/100\n",
      "6/6 [==============================] - 0s 995us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 84/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 85/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 86/100\n",
      "6/6 [==============================] - 0s 998us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 87/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 88/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 89/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 90/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 91/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 92/100\n",
      "6/6 [==============================] - 0s 998us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 93/100\n",
      "6/6 [==============================] - 0s 998us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 94/100\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 95/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 96/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 97/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 98/100\n",
      "6/6 [==============================] - 0s 997us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 99/100\n",
      "6/6 [==============================] - 0s 797us/step - loss: 0.0000e+00 - accuracy: 0.6476\n",
      "Epoch 100/100\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.6476\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2ab9689aa00>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=100,batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38929f09-7fdf-4001-b12c-b1a3eb7aa7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002AB9AE50F70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87ef3db5-6dd0-45fd-93c3-3c4bb924d70e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7111111111111111"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc=accuracy_score(y_pred,y_test)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fb5617-222d-4d8a-bc89-56a26b267177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
